{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier,AdaBoostClassifier,StackingClassifier,VotingClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#lettura database\n",
    "data=pd.read_csv(\"credit_risk_dataset.csv\")\n",
    "print('shape originale', data.shape) \n",
    "print(data.info()) \n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Procedo a cambiare il nome alle colonne per non doverle tradurle in testa ogni talvolta le leggo.\n",
    "colonne_originali = data.columns\n",
    "nuove_colonne = ['Età', 'Reddito', 'Diritto Abitazione', 'Tempo Attuale Impiego', 'Motivazione credito', 'Punteggio Credito', 'Ammontare del Credito', 'Interesse sul Credito', 'Status', 'Percentuale Credito', 'Cronologia Status', 'Cronologia Crediti']\n",
    "colonne = dict(zip(colonne_originali, nuove_colonne)) \n",
    "data.rename(columns=colonne, inplace=True) \n",
    "print(colonne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ogni banca può applicare l'interesse che vuole, quindi non ha senso avere questo dato.\n",
    "data.drop(['Interesse sul Credito'],axis=1,inplace=True)\n",
    "\n",
    "#togliamo le righe duplicate, cosi evitiamo che vadano a finire sia all'interno del train che all'interno del test.\n",
    "print(f'Ho {data.duplicated().value_counts()[True]} dati duplicati') \n",
    "data.drop_duplicates(inplace=True)\n",
    "print('Dimensione del database una volte tolte le righe duplicate',data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percento di data null: \\n {data.isna().sum()/data.shape[0]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi della variabile 'Tempo Attuale Impiego' \n",
    "data['Tempo Attuale Impiego'].plot.hist(bins=40)\n",
    "plt.axvline(data['Tempo Attuale Impiego'].mode()[0], c='red')\n",
    "plt.axvline(data['Tempo Attuale Impiego'].mean(), c='b')\n",
    "plt.axvline(data['Tempo Attuale Impiego'].median(), c='y');\n",
    "plt.axvline(data['Tempo Attuale Impiego'].quantile(.75), c='black', linestyle='--');\n",
    "\n",
    "#Riempo i valori null\n",
    "data['Tempo Attuale Impiego'].fillna(data['Tempo Attuale Impiego'].mode()[0], inplace=True)\n",
    "\n",
    "#faccio un test per vedere che effettivamente sono stati eliminati\n",
    "print(f'Percento di data null: \\n {data.isna().sum()/data.shape[0]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alcune finanziarie e banche valutano richieste di finanziamento purché il cliente, alla fine del finanziamento, non deve superare i 75 anni di età\n",
    "mask_età_abile_per_crediti = (data.Età >= 18) & (data.Età <= 75) \n",
    "\n",
    "#L'aspettativa di vita in USA è in caduta libera da circa un decennio: è arrivata a 76,1 anni nel 2021\n",
    "mask_tempo_utile_lavorativo = (data['Tempo Attuale Impiego'] <= (76.1 - 18))  \n",
    "\n",
    "data = data[mask_età_abile_per_crediti & mask_tempo_utile_lavorativo]\n",
    "print('Dimensione del database tenendo in conto l\\'età anagrafica del cliente',data.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[df['Reddito'] < 3.5e5].person_income.plot.hist(bins=40)\n",
    "print(data['Reddito'].describe())\n",
    "data[data['Reddito'] < 3.5e5]['Reddito'].plot.hist(bins=40)\n",
    "plt.title('Distribuzione reddito.')\n",
    "\n",
    "#Procedo quindi togliere gli outlier\n",
    "data = data[data['Reddito'] < 3.5e5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccol=data.select_dtypes(include=[\"object\"]).columns\n",
    "ncol=data.select_dtypes(include=[\"int\",\"float\"]).columns\n",
    "print(ccol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = pd.DataFrame(data[ncol])  \n",
    "# Cancello la colonna Status prima della visualizzazione\n",
    "num_cols_hist = num_cols.drop(['Status'], axis=1)\n",
    "# Visulizziamo la distribuzione per ogni variabile numerica\n",
    "plt.figure(figsize=(12,16))\n",
    "\n",
    "for i, col in enumerate(num_cols_hist.columns):\n",
    "    idx = int('42'+ str(i+1))\n",
    "    plt.subplot(idx)\n",
    "    sns.histplot(num_cols_hist[col], color='deeppink', \n",
    "                 kde_kws={'color': 'forest green', 'lw': 2, 'label': 'KDE'}) # KDE: the kernel density estimate\n",
    "    plt.title('Distribuzione del dato: ' +col, fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.legend(['KDE'], prop={\"size\":12})\n",
    "\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.35,\n",
    "                    wspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data, hue='Status') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"The number of Categorical columns are:\",len(ccol))\n",
    "print(\"The number of Numerical columns are:\",len(ncol)) \n",
    "\n",
    "for colonna in ccol:\n",
    "    print(f'\\n {colonna}: \\n {data[colonna].value_counts(normalize=True).sort_index()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Status'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_num = StandardScaler().fit_transform(data[num_cols_hist.columns].values)\n",
    "ohe = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "X_cat = ohe.fit_transform(data[ccol].values)\n",
    "X = np.concatenate([X_num, X_cat], axis=1) \n",
    "\n",
    "y = data['Status']\n",
    "\n",
    "feature_names = num_cols_hist.columns.tolist() + ohe.get_feature_names_out(ccol).tolist() \n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_hist.columns \n",
    "df = pd.DataFrame(X_num, columns = num_cols_hist.columns)\n",
    "# Visulizziamo la distribuzione per ogni variabile numerica, dopo averle scalato.\n",
    "plt.figure(figsize=(12,16))\n",
    "\n",
    "for i, col in enumerate(df.columns):\n",
    "    idx = int('42'+ str(i+1))\n",
    "    plt.subplot(idx)\n",
    "    sns.histplot(df[col], color='deeppink', \n",
    "                 kde_kws={'color': 'forest green', 'lw': 2, 'label': 'KDE'}) # KDE: the kernel density estimate\n",
    "    plt.title('Distribuzione del dato: ' +col, fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.legend(['KDE'], prop={\"size\":12})\n",
    "\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.35,\n",
    "                    wspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) \n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controllo che abbia manenuto le proporzioni,nel target, dopo il shuffle/split\n",
    "print(y.value_counts(normalize=True) * 100, y_test.value_counts(normalize=True) * 100 , y_train.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(20, 10))\n",
    "\n",
    "plot_tree(clf, ax=ax, fontsize=10, filled=True, proportion=True, max_depth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred=neigh.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = RandomForestClassifier(n_estimators=1000,max_depth=100, n_jobs=11)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred)) \n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(data=confusion_matrix(y_test,y_pred),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelli = [\n",
    "DecisionTreeClassifier(criterion='entropy'),\n",
    "KNeighborsClassifier(n_neighbors=10),\n",
    "RandomForestClassifier(n_estimators=1000,max_depth=100, n_jobs=11)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "entries = []\n",
    "for modello in modelli:\n",
    "    nome_modello = modello.__class__.__name__\n",
    "    clsffit = modello.fit(X_train,y_train)\n",
    "    print('\\t\\tCLASSIFICATIION METRICS \"{}\":\\n'.format(nome_modello))\n",
    "    print(classification_report(y_test, modello.predict(X_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
